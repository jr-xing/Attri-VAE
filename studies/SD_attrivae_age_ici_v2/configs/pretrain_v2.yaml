# Stage 1: Pre-train VAE for Reconstruction - V2 (Fixed Posterior Collapse)
#
# CHANGES from v1:
# - Much lower beta: 0.0001 instead of 0.01 (100x smaller)
# - Added free_bits: 0.5 to prevent posterior collapse
# - Longer warmup: 100 epochs instead of 50
#
# The problem in v1 was POSTERIOR COLLAPSE:
# - KL loss went to ~0, meaning encoder outputs z ~ N(0,1) for all inputs
# - Latent space carries no information
# - Decoder outputs blurry average image
#
# Solutions applied:
# 1. Much lower beta to not overwhelm reconstruction
# 2. Free bits: minimum KL per dimension (ensures latent space is used)

# Data configuration
data:
  data_file: "/gpfs/gibbs/project/kwan/jx332/code/2025-09-LGE-CHIP-Classification-V2/data/2025-06-01-onc-cohort-144-with-serial-scans-and-103-LGE-masks.npy"
  spreadsheet: "/gpfs/gibbs/project/kwan/jx332/code/2025-09-LGE-CHIP-Classification-V2/link_project_data/CHIP ICI MI CM outcomes - Updated 2025-10-09.xlsx"
  val_fraction: 0.2
  seed: 42

# Model architecture
model:
  image_channels: 1
  h_dim: 96
  latent_size: 64
  n_filters_enc: [8, 16, 32, 64, 2]
  n_filters_dec: [64, 32, 16, 8, 4, 2]
  target_size: [80, 80, 80]

# Training parameters
training:
  batch_size: 8
  epochs: 1000              # Increased from 300 - loss still decreasing
  learning_rate: 0.001
  num_workers: 4
  augment: true

# Loss weights - FIXED FOR POSTERIOR COLLAPSE
loss:
  recon_param: 1.0          # Reconstruction loss weight
  beta: 0.0001              # MUCH smaller KL weight (was 0.01)
  beta_warmup_epochs: 100   # Longer warmup (was 50)
  free_bits: 0.5            # NEW: Minimum KL per dimension to prevent collapse

# Output
output_dir: "/gpfs/gibbs/project/kwan/jx332/code/2025-12-Attri-VAE/studies/SD_attrivae_age_ici_v2/outputs/pretrain"
